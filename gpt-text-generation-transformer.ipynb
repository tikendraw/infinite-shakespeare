{"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tqdm\nimport math\nfrom dataclasses import dataclass\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nimport matplotlib.pyplot as plt\nfrom itertools import permutations\nfrom torch.utils.data import DataLoader, Dataset\n\n","metadata":{"id":"B1qKLvilnI5C","execution":{"iopub.status.busy":"2023-06-26T15:33:23.278117Z","iopub.execute_input":"2023-06-26T15:33:23.278461Z","iopub.status.idle":"2023-06-26T15:33:27.152068Z","shell.execute_reply.started":"2023-06-26T15:33:23.278433Z","shell.execute_reply":"2023-06-26T15:33:27.150944Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/tikendraw/nanoGPT/main/shakespeare.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdymXMZcO6Pe","outputId":"86bc6eca-c055-4817-bbfd-076404c765e1","execution":{"iopub.status.busy":"2023-06-26T15:33:27.155126Z","iopub.execute_input":"2023-06-26T15:33:27.156081Z","iopub.status.idle":"2023-06-26T15:33:29.070276Z","shell.execute_reply.started":"2023-06-26T15:33:27.156045Z","shell.execute_reply":"2023-06-26T15:33:29.068685Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2023-06-26 15:33:28--  https://raw.githubusercontent.com/tikendraw/nanoGPT/main/shakespeare.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: ‘shakespeare.txt’\n\nshakespeare.txt     100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n\n2023-06-26 15:33:28 (19.0 MB/s) - ‘shakespeare.txt’ saved [1115394/1115394]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('shakespeare.txt', 'r') as f:\n    text = f.readlines()","metadata":{"id":"GZjgQq2Hnzns","execution":{"iopub.status.busy":"2023-06-26T15:33:29.072126Z","iopub.execute_input":"2023-06-26T15:33:29.072508Z","iopub.status.idle":"2023-06-26T15:33:29.089522Z","shell.execute_reply.started":"2023-06-26T15:33:29.072456Z","shell.execute_reply":"2023-06-26T15:33:29.088634Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"len(text), type(text)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAct-IRsn9YS","outputId":"22eee59f-e7e7-43da-eb44-db02175b9968","execution":{"iopub.status.busy":"2023-06-26T15:33:29.095352Z","iopub.execute_input":"2023-06-26T15:33:29.097531Z","iopub.status.idle":"2023-06-26T15:33:29.109678Z","shell.execute_reply.started":"2023-06-26T15:33:29.097496Z","shell.execute_reply":"2023-06-26T15:33:29.108616Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(40000, list)"},"metadata":{}}]},{"cell_type":"code","source":"text =  ' '.join(text)","metadata":{"id":"Jd6y3Hrvn_du","execution":{"iopub.status.busy":"2023-06-26T15:33:29.114160Z","iopub.execute_input":"2023-06-26T15:33:29.116338Z","iopub.status.idle":"2023-06-26T15:33:29.125968Z","shell.execute_reply.started":"2023-06-26T15:33:29.116306Z","shell.execute_reply":"2023-06-26T15:33:29.124951Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text[:44]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vC1Upsg-oIYC","outputId":"30c8897b-813e-4003-caa9-26b20d20d30d","execution":{"iopub.status.busy":"2023-06-26T15:33:29.130848Z","iopub.execute_input":"2023-06-26T15:33:29.133292Z","iopub.status.idle":"2023-06-26T15:33:29.143379Z","shell.execute_reply.started":"2023-06-26T15:33:29.133260Z","shell.execute_reply":"2023-06-26T15:33:29.142338Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'First Citizen:\\n Before we proceed any furthe'"},"metadata":{}}]},{"cell_type":"code","source":"chars = ''.join(sorted(set(text)))\nchars","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"WSlXBsfFogV7","outputId":"18a95e13-befd-485d-9db7-76bc88a0fd3f","execution":{"iopub.status.busy":"2023-06-26T15:33:29.147824Z","iopub.execute_input":"2023-06-26T15:33:29.148387Z","iopub.status.idle":"2023-06-26T15:33:29.185148Z","shell.execute_reply.started":"2023-06-26T15:33:29.148352Z","shell.execute_reply":"2023-06-26T15:33:29.184138Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenization","metadata":{"id":"A64yraEWrzCw"}},{"cell_type":"markdown","source":"We will create 2 character level token","metadata":{"id":"_C-1wLfXr2UY"}},{"cell_type":"code","source":"","metadata":{"id":"2lzpRfKpqFME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = permutations(chars,2)\na = list(a)","metadata":{"id":"eH2mUWeHqn9Q","execution":{"iopub.status.busy":"2023-06-26T15:33:29.189638Z","iopub.execute_input":"2023-06-26T15:33:29.191863Z","iopub.status.idle":"2023-06-26T15:33:29.202357Z","shell.execute_reply.started":"2023-06-26T15:33:29.191827Z","shell.execute_reply":"2023-06-26T15:33:29.201416Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# permuation does not include chars like aa, bb 99 , doin that\nfor i in zip(chars, chars):\n    a.append(''.join(i))","metadata":{"id":"owLIqnR63otp","execution":{"iopub.status.busy":"2023-06-26T15:33:29.206937Z","iopub.execute_input":"2023-06-26T15:33:29.209630Z","iopub.status.idle":"2023-06-26T15:33:29.216082Z","shell.execute_reply.started":"2023-06-26T15:33:29.209587Z","shell.execute_reply":"2023-06-26T15:33:29.215178Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# joining tuples\na = [''.join(i) for i in a]  # 7140 combination possible\n\n# keeping only tokens that exist in data\na = [i for i in a if i in text] # 2018 combination exists in data\n","metadata":{"id":"3Fow491Eq-_Z","execution":{"iopub.status.busy":"2023-06-26T15:33:29.223921Z","iopub.execute_input":"2023-06-26T15:33:29.225996Z","iopub.status.idle":"2023-06-26T15:33:31.364470Z","shell.execute_reply.started":"2023-06-26T15:33:29.225966Z","shell.execute_reply":"2023-06-26T15:33:31.363523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"stoi = {i:num for num, i in enumerate(a,1)} # token starts with 34\nstoi[\"UNK\"] = 0\nitos = {i:num for num, i in stoi.items()}","metadata":{"id":"pz9GMuY2rpej","execution":{"iopub.status.busy":"2023-06-26T15:33:31.365874Z","iopub.execute_input":"2023-06-26T15:33:31.366219Z","iopub.status.idle":"2023-06-26T15:33:31.372358Z","shell.execute_reply.started":"2023-06-26T15:33:31.366186Z","shell.execute_reply":"2023-06-26T15:33:31.371520Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def encode(x:str):\n    if len(x.split())%2==1:\n        x += ' '\n    x = [x[i:i+2] for i in range(0, len(x), 2)]\n    return [stoi[i] for i in x]","metadata":{"id":"wn5rtUyluQ_f","execution":{"iopub.status.busy":"2023-06-26T15:33:31.374062Z","iopub.execute_input":"2023-06-26T15:33:31.374800Z","iopub.status.idle":"2023-06-26T15:33:31.383404Z","shell.execute_reply.started":"2023-06-26T15:33:31.374769Z","shell.execute_reply":"2023-06-26T15:33:31.382487Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"VOCAB_SIZE = len(stoi.values())\nVOCAB_SIZE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqqw4YuZZUcC","outputId":"e1f81352-0feb-4c2f-fd57-1c864ac282a0","execution":{"iopub.status.busy":"2023-06-26T15:33:31.384754Z","iopub.execute_input":"2023-06-26T15:33:31.385077Z","iopub.status.idle":"2023-06-26T15:33:31.396502Z","shell.execute_reply.started":"2023-06-26T15:33:31.385046Z","shell.execute_reply":"2023-06-26T15:33:31.395676Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1355"},"metadata":{}}]},{"cell_type":"code","source":"def replace_numbers_greater_than(numbers, limit:int, replace_with: int =0):\n    return [num if 0 < num <= limit else replace_with for num in numbers]","metadata":{"id":"8lzK0ZwAhR4w","execution":{"iopub.status.busy":"2023-06-26T15:33:31.398937Z","iopub.execute_input":"2023-06-26T15:33:31.400383Z","iopub.status.idle":"2023-06-26T15:33:31.405972Z","shell.execute_reply.started":"2023-06-26T15:33:31.400359Z","shell.execute_reply":"2023-06-26T15:33:31.405134Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"RESERVED_TOKEN=0 # for unknown token\n\ndef decode(x):\n    x = replace_numbers_greater_than(x, limit=VOCAB_SIZE-1, replace_with=RESERVED_TOKEN)\n    return ''.join(itos[i] for i in x).strip()\n","metadata":{"id":"L2fWtQzCz5LO","execution":{"iopub.status.busy":"2023-06-26T15:33:31.407440Z","iopub.execute_input":"2023-06-26T15:33:31.407789Z","iopub.status.idle":"2023-06-26T15:33:31.415472Z","shell.execute_reply.started":"2023-06-26T15:33:31.407758Z","shell.execute_reply":"2023-06-26T15:33:31.414648Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"encode('tikendr'), decode(encode('tikendr'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqptllxRunED","outputId":"58281c0a-0dca-489c-9906-998963ce6aa7","execution":{"iopub.status.busy":"2023-06-26T15:33:31.416948Z","iopub.execute_input":"2023-06-26T15:33:31.417261Z","iopub.status.idle":"2023-06-26T15:33:31.427093Z","shell.execute_reply.started":"2023-06-26T15:33:31.417232Z","shell.execute_reply":"2023-06-26T15:33:31.426150Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"([1189, 938, 1020, 1105], 'tikendr')"},"metadata":{}}]},{"cell_type":"code","source":"x = encode(text)","metadata":{"id":"z4oSXKD610W1","execution":{"iopub.status.busy":"2023-06-26T15:33:31.428627Z","iopub.execute_input":"2023-06-26T15:33:31.429118Z","iopub.status.idle":"2023-06-26T15:33:31.639387Z","shell.execute_reply.started":"2023-06-26T15:33:31.429067Z","shell.execute_reply":"2023-06-26T15:33:31.638456Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"len(x)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8VVWcMd2PlD","outputId":"dcb0bfa8-b12b-4b94-962a-6943a77b3409","execution":{"iopub.status.busy":"2023-06-26T15:33:31.640708Z","iopub.execute_input":"2023-06-26T15:33:31.641133Z","iopub.status.idle":"2023-06-26T15:33:31.647192Z","shell.execute_reply.started":"2023-06-26T15:33:31.641100Z","shell.execute_reply":"2023-06-26T15:33:31.646368Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"577697"},"metadata":{}}]},{"cell_type":"markdown","source":"# Config","metadata":{"id":"KS7WfYpO9oD2"}},{"cell_type":"code","source":"len(stoi)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bv-s8gko39qJ","outputId":"df1e8434-0438-47d5-a9d1-34023154737f","execution":{"iopub.status.busy":"2023-06-26T15:33:31.648581Z","iopub.execute_input":"2023-06-26T15:33:31.649134Z","iopub.status.idle":"2023-06-26T15:33:31.658967Z","shell.execute_reply.started":"2023-06-26T15:33:31.649103Z","shell.execute_reply":"2023-06-26T15:33:31.657959Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1355"},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass GPTConfig:\n    block_size: int = 500 # context_length\n    vocab_size: int = len(stoi)  # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n    n_layer: int = 4\n    n_head: int = 4\n    n_embd: int = 64\n    dropout: float = 0.05\n    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nconfig = GPTConfig()\nconfig","metadata":{"id":"Br2b1WpY34FN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c91e200-3848-416f-f346-43f42c931ae9","execution":{"iopub.status.busy":"2023-06-26T15:33:31.660575Z","iopub.execute_input":"2023-06-26T15:33:31.660944Z","iopub.status.idle":"2023-06-26T15:33:31.698847Z","shell.execute_reply.started":"2023-06-26T15:33:31.660911Z","shell.execute_reply":"2023-06-26T15:33:31.697988Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"GPTConfig(block_size=500, vocab_size=1355, n_layer=4, n_head=4, n_embd=64, dropout=0.05, bias=True, device='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"# make DATA","metadata":{"id":"gwbEbEAx-MOV"}},{"cell_type":"code","source":"test_size = int(len(x)*.9)\ntrain, test = x[:test_size], x[test_size:]\n\nprint( 'train: ',len(train), ' + ' , 'test: ',len(test), ' = ',len(x))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkAdqCXM0KzS","outputId":"c4add411-ec78-4dee-8724-4fb18e2803ac","execution":{"iopub.status.busy":"2023-06-26T15:33:31.700322Z","iopub.execute_input":"2023-06-26T15:33:31.700942Z","iopub.status.idle":"2023-06-26T15:33:31.713193Z","shell.execute_reply.started":"2023-06-26T15:33:31.700911Z","shell.execute_reply":"2023-06-26T15:33:31.712316Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"train:  519927  +  test:  57770  =  577697\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_dataset(numbers, window_size):\n    n_windows = len(numbers) - window_size\n\n    X = np.array([numbers[i:i+window_size] for i in range(n_windows)])\n    y = np.array([numbers[i+1:i+window_size+1] for i in range(n_windows)])\n\n    print(\"Number of windows:\", len(X))\n    print(\"Number of corresponding outputs:\", len(y), end = '\\n')\n\n    return X, y\n","metadata":{"id":"cYSJV01z599l","execution":{"iopub.status.busy":"2023-06-26T15:33:31.716845Z","iopub.execute_input":"2023-06-26T15:33:31.718601Z","iopub.status.idle":"2023-06-26T15:33:31.729131Z","shell.execute_reply.started":"2023-06-26T15:33:31.718569Z","shell.execute_reply":"2023-06-26T15:33:31.728286Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"window_size = 10\n\nxtr, ytr = create_dataset(train, config.block_size)\nxts, yts = create_dataset(test, config.block_size)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-lsFRWt69cg","outputId":"a806663b-2017-48cb-a047-da7ce3a8fe4e","execution":{"iopub.status.busy":"2023-06-26T15:33:31.730266Z","iopub.execute_input":"2023-06-26T15:33:31.730711Z","iopub.status.idle":"2023-06-26T15:34:59.151574Z","shell.execute_reply.started":"2023-06-26T15:33:31.730680Z","shell.execute_reply":"2023-06-26T15:34:59.150578Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Number of windows: 519427\nNumber of corresponding outputs: 519427\nNumber of windows: 57270\nNumber of corresponding outputs: 57270\n","output_type":"stream"}]},{"cell_type":"code","source":"xtr.shape, ytr.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AufidqxGU6ey","outputId":"d80fd331-8872-47a2-9b25-70687c71df02","execution":{"iopub.status.busy":"2023-06-26T16:16:15.407030Z","iopub.execute_input":"2023-06-26T16:16:15.407573Z","iopub.status.idle":"2023-06-26T16:16:15.415432Z","shell.execute_reply.started":"2023-06-26T16:16:15.407532Z","shell.execute_reply":"2023-06-26T16:16:15.414529Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"((519427, 500), (519427, 500))"},"metadata":{}}]},{"cell_type":"code","source":"# xtr[0], ytr[0] # shifted by one value","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wrHVKzstidM","outputId":"d8612ad1-b553-4701-e729-f9c519ab9b69","execution":{"iopub.status.busy":"2023-06-26T16:16:17.018408Z","iopub.execute_input":"2023-06-26T16:16:17.018912Z","iopub.status.idle":"2023-06-26T16:16:17.024069Z","shell.execute_reply.started":"2023-06-26T16:16:17.018873Z","shell.execute_reply":"2023-06-26T16:16:17.022904Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{"id":"SICO1mZoX1N9"}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7xmzke_R7AFz","outputId":"bdb9198e-2d66-4139-8085-43c38eba9796","execution":{"iopub.status.busy":"2023-06-26T16:16:18.881357Z","iopub.execute_input":"2023-06-26T16:16:18.882028Z","iopub.status.idle":"2023-06-26T16:16:18.888868Z","shell.execute_reply.started":"2023-06-26T16:16:18.881993Z","shell.execute_reply":"2023-06-26T16:16:18.887871Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n\n        return self.x[idx],self.y[idx]\n\n\n\ndataset = CustomDataset(xtr, ytr)\ntestdataset = CustomDataset(xts, yts)\n\nbatch_size = 32\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\ntestdataloader = DataLoader(testdataset, batch_size=batch_size)\n\n\nfor inputs, targets in dataloader:\n    # inputs = batch['input']\n    # targets = batch['target']\n    print(inputs.shape, targets.shape)\n    break\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIHUUVrPXy28","outputId":"822a4394-b8ae-486f-ac9f-76f4244ef5a4","execution":{"iopub.status.busy":"2023-06-26T16:16:19.443746Z","iopub.execute_input":"2023-06-26T16:16:19.444096Z","iopub.status.idle":"2023-06-26T16:16:19.491605Z","shell.execute_reply.started":"2023-06-26T16:16:19.444068Z","shell.execute_reply":"2023-06-26T16:16:19.490494Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"torch.Size([32, 500]) torch.Size([32, 500])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"t9NrC91g7DoN"}},{"cell_type":"code","source":"class CausalSelfAttention(nn.Module):\n\n    def __init__(self, config):\n        super().__init__()\n        assert config.n_embd % config.n_head == 0\n        # key, query, value projections for all heads, but in a batch\n        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n        # output projection\n        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n        # regularization\n        self.attn_dropout = nn.Dropout(config.dropout)\n        self.resid_dropout = nn.Dropout(config.dropout)\n        self.n_head = config.n_head\n        self.n_embd = config.n_embd\n        self.dropout = config.dropout\n\n        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n        if not self.flash:\n            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n            # causal mask to ensure that attention is only applied to the left in the input sequence\n            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n                                        .view(1, 1, config.block_size, config.block_size))\n\n    def forward(self, x):\n        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n\n        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n        if self.flash:\n            # efficient attention using Flash Attention CUDA kernels\n            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n            print('y  : ', y.shape)\n        else:\n            # manual implementation of attention\n            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n            att = F.softmax(att, dim=-1)\n            att = self.attn_dropout(att)\n            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n\n        # output projection\n        y = self.resid_dropout(self.c_proj(y))\n        return y\n\ninputs = torch.randn(config.n_layer, config.block_size, config.n_embd)\n\nattention = CausalSelfAttention(config)\noutput = attention(inputs)\nprint(output.size())  # Shape: (seq_len, batch_size, embed_dim)\n","metadata":{"id":"3i9S2PTW7nQ3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"65992a3e-42e4-4b04-f9e0-3b1e7b84cba6","execution":{"iopub.status.busy":"2023-06-26T15:34:59.319349Z","iopub.execute_input":"2023-06-26T15:34:59.320078Z","iopub.status.idle":"2023-06-26T15:34:59.468175Z","shell.execute_reply.started":"2023-06-26T15:34:59.320046Z","shell.execute_reply":"2023-06-26T15:34:59.466359Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"y  :  torch.Size([4, 4, 500, 16])\ntorch.Size([4, 500, 64])\n","output_type":"stream"}]},{"cell_type":"code","source":"q = torch.randn(1, config.block_size, 8)\nk = torch.randn(1, config.block_size, 8)\nv = torch.randn(1, config.block_size, 8)\n","metadata":{"id":"CZT5V2sSM633","execution":{"iopub.status.busy":"2023-06-26T15:34:59.470452Z","iopub.execute_input":"2023-06-26T15:34:59.471148Z","iopub.status.idle":"2023-06-26T15:34:59.476833Z","shell.execute_reply.started":"2023-06-26T15:34:59.471112Z","shell.execute_reply":"2023-06-26T15:34:59.475941Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"<img src='https://storrs.io/content/images/2021/08/Screen-Shot-2021-08-07-at-7.51.37-AM.png'>","metadata":{"id":"PLoGcn-d7nJs"}},{"cell_type":"markdown","source":"# Scale Dot Product","metadata":{"id":"fhy-EKJz6hcN"}},{"cell_type":"code","source":"mask = torch.tril(torch.ones(config.block_size,config.block_size))\nmask, q.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oa4IgmyvTVWc","outputId":"7ca718f9-0684-476b-d420-2de72c7423f3","execution":{"iopub.status.busy":"2023-06-26T15:34:59.478606Z","iopub.execute_input":"2023-06-26T15:34:59.478932Z","iopub.status.idle":"2023-06-26T15:34:59.501964Z","shell.execute_reply.started":"2023-06-26T15:34:59.478903Z","shell.execute_reply":"2023-06-26T15:34:59.500983Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n         [1., 1., 0.,  ..., 0., 0., 0.],\n         [1., 1., 1.,  ..., 0., 0., 0.],\n         ...,\n         [1., 1., 1.,  ..., 1., 0., 0.],\n         [1., 1., 1.,  ..., 1., 1., 0.],\n         [1., 1., 1.,  ..., 1., 1., 1.]]),\n torch.Size([1, 500, 8]))"},"metadata":{}}]},{"cell_type":"code","source":"def scale_dot_product(q,k,v, mask=None, return_attention = False, print_shape=False, show_attention=False):\n\n    d_embed = q.shape[-1]\n\n    a = (q @ k.transpose(-2,-1)) / d_embed**(1/2)\n\n    if mask is not None:\n        # for visual purpose\n        if show_attention:\n            visible_attention_score = a.masked_fill(mask == 0, 0)\n            plt.imshow(visible_attention_score.squeeze())\n        # real\n        attention_score = a.masked_fill(mask == 0, -9e20)\n\n    attention_score = F.softmax(a, dim=-1)\n\n    values = attention_score @ v\n\n    if print_shape:\n        print('q: ',q.shape, '\\nk: ', k.shape, '\\nv: ', k.shape)\n        print()\n\n        print('values   : ',values.shape)\n        print('attention: ',attention_score.shape)\n\n    if return_attention:\n        return values, attention_score\n    else:\n        return values\n\nval, attention_score = scale_dot_product(q,k,v,mask=mask, return_attention = True ,print_shape=True, show_attention=False)","metadata":{"id":"3QeqWUs57nG4","colab":{"base_uri":"https://localhost:8080/","height":545},"outputId":"adcabeff-debf-49ee-8a98-2d560595f036","execution":{"iopub.status.busy":"2023-06-26T15:34:59.503413Z","iopub.execute_input":"2023-06-26T15:34:59.503855Z","iopub.status.idle":"2023-06-26T15:34:59.517514Z","shell.execute_reply.started":"2023-06-26T15:34:59.503824Z","shell.execute_reply":"2023-06-26T15:34:59.516434Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"q:  torch.Size([1, 500, 8]) \nk:  torch.Size([1, 500, 8]) \nv:  torch.Size([1, 500, 8])\n\nvalues   :  torch.Size([1, 500, 8])\nattention:  torch.Size([1, 500, 500])\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.imshow(val.squeeze())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"id":"2yFaCddVU_aU","outputId":"a57bb378-14fb-4a4b-8322-9ffea51e9a5f","execution":{"iopub.status.busy":"2023-06-26T15:34:59.519040Z","iopub.execute_input":"2023-06-26T15:34:59.519510Z","iopub.status.idle":"2023-06-26T15:34:59.743314Z","shell.execute_reply.started":"2023-06-26T15:34:59.519463Z","shell.execute_reply":"2023-06-26T15:34:59.742392Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7a8110ad09d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def scaled_dot_product(q, k, v, mask=None):\n    d_k = q.size()[-1]\n    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n    attn_logits = attn_logits / math.sqrt(d_k)\n    if mask is not None:\n        attn_logits = attn_logits.masked_fill(mask == 0, -9e20)\n    attention = F.softmax(attn_logits, dim=-1)\n    values = torch.matmul(attention, v)\n    return values","metadata":{"id":"owFQIb6hoA3S","execution":{"iopub.status.busy":"2023-06-26T15:34:59.744715Z","iopub.execute_input":"2023-06-26T15:34:59.745033Z","iopub.status.idle":"2023-06-26T15:34:59.752012Z","shell.execute_reply.started":"2023-06-26T15:34:59.745002Z","shell.execute_reply":"2023-06-26T15:34:59.751154Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Causal MultiheadAttention","metadata":{"id":"G19p3jvyoArh"}},{"cell_type":"markdown","source":"<img src='https://coriva.eu.org/images/multiheadattention.png'>","metadata":{"id":"bF8EX48j9jqX"}},{"cell_type":"code","source":"\nclass CausalSelfAttention(nn.Module):\n\n    def __init__(self, config):\n        super().__init__()\n        assert config.n_embd % config.n_head == 0\n        # key, query, value projections for all heads, but in a batch\n        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n        # output projection\n        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n        # regularization\n        self.attn_dropout = nn.Dropout(config.dropout)\n        self.resid_dropout = nn.Dropout(config.dropout)\n        self.n_head = config.n_head\n        self.n_embd = config.n_embd\n        self.dropout = config.dropout\n\n        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n        if not self.flash:\n            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n            # causal mask to ensure that attention is only applied to the left in the input sequence\n            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n                                        .view(1, 1, config.block_size, config.block_size))\n\n    def forward(self, x):\n        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n\n        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n\n        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n        if self.flash:\n            # efficient attention using Flash Attention CUDA kernels\n            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n        else:\n            # manual implementation of attention\n            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n            att = F.softmax(att, dim=-1)\n            att = self.attn_dropout(att)\n            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n\n        # output projection\n        y = self.resid_dropout(self.c_proj(y))\n        return y\n","metadata":{"id":"AgjrLwshEfHv","execution":{"iopub.status.busy":"2023-06-26T15:34:59.753771Z","iopub.execute_input":"2023-06-26T15:34:59.754536Z","iopub.status.idle":"2023-06-26T15:34:59.769453Z","shell.execute_reply.started":"2023-06-26T15:34:59.754503Z","shell.execute_reply":"2023-06-26T15:34:59.768418Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"att = CausalSelfAttention(config)\ninputs = torch.randn(1, config.block_size, config.n_embd)\nprint('input: ', inputs.shape)\ny = att(inputs)\nprint('output: ', y.shape)","metadata":{"id":"zJAJfIFroAlP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb4e1e63-1e4a-43d8-da3d-5467e84807d4","execution":{"iopub.status.busy":"2023-06-26T15:34:59.770784Z","iopub.execute_input":"2023-06-26T15:34:59.771346Z","iopub.status.idle":"2023-06-26T15:34:59.797957Z","shell.execute_reply.started":"2023-06-26T15:34:59.771316Z","shell.execute_reply":"2023-06-26T15:34:59.797077Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"input:  torch.Size([1, 500, 64])\noutput:  torch.Size([1, 500, 64])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LayerNorm","metadata":{"id":"UrYsAhL0oAiI"}},{"cell_type":"code","source":"ndim = 4\nweight = nn.Parameter(torch.ones(ndim))\nweight","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CMZJRDq8zVT","outputId":"8990eeb6-8897-4378-e242-2545e77c5dcb","execution":{"iopub.status.busy":"2023-06-26T15:34:59.799146Z","iopub.execute_input":"2023-06-26T15:34:59.799762Z","iopub.status.idle":"2023-06-26T15:34:59.807857Z","shell.execute_reply.started":"2023-06-26T15:34:59.799729Z","shell.execute_reply":"2023-06-26T15:34:59.806831Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Parameter containing:\ntensor([1., 1., 1., 1.], requires_grad=True)"},"metadata":{}}]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n    def __init__(self, ndim, bias):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(ndim))\n        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n\n    def forward(self, input):\n        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)","metadata":{"id":"SlemOogkoAVr","execution":{"iopub.status.busy":"2023-06-26T15:34:59.809272Z","iopub.execute_input":"2023-06-26T15:34:59.809744Z","iopub.status.idle":"2023-06-26T15:34:59.817144Z","shell.execute_reply.started":"2023-06-26T15:34:59.809711Z","shell.execute_reply":"2023-06-26T15:34:59.816217Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"lay_norm = LayerNorm(config.n_embd, False)\nl = lay_norm(y)\nprint(l.shape)","metadata":{"id":"Kv4ynfMqoATA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a745c49-78c6-48a2-f4ee-52b0d47f8f16","execution":{"iopub.status.busy":"2023-06-26T15:34:59.818279Z","iopub.execute_input":"2023-06-26T15:34:59.820193Z","iopub.status.idle":"2023-06-26T15:34:59.830692Z","shell.execute_reply.started":"2023-06-26T15:34:59.820161Z","shell.execute_reply":"2023-06-26T15:34:59.829721Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"torch.Size([1, 500, 64])\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.subplot(1,2,1)\nplt.hist(y[0][0].detach().numpy())\nplt.subplot(1,2,2)\nplt.hist(l[0][0].detach().numpy())","metadata":{"id":"LGh3NAPUoAP5","colab":{"base_uri":"https://localhost:8080/","height":522},"outputId":"581de0e4-c60d-482e-fb9b-1f152f3dac71","execution":{"iopub.status.busy":"2023-06-26T15:34:59.832271Z","iopub.execute_input":"2023-06-26T15:34:59.832652Z","iopub.status.idle":"2023-06-26T15:35:00.225373Z","shell.execute_reply.started":"2023-06-26T15:34:59.832620Z","shell.execute_reply":"2023-06-26T15:35:00.224413Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(array([ 1.,  3.,  2.,  8.,  4., 12., 12., 10.,  8.,  4.]),\n array([-2.61919332, -2.175102  , -1.73101068, -1.28691947, -0.84282815,\n        -0.39873683,  0.04535446,  0.48944575,  0.93353707,  1.37762833,\n         1.82171965]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# MLP","metadata":{"id":"B1Kf1TjIoAMg"}},{"cell_type":"code","source":"class MLP(nn.Module):\n\n    def __init__(self, config):\n        super().__init__()\n        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n        self.gelu    = nn.GELU()\n        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n        self.dropout = nn.Dropout(config.dropout)\n\n    def forward(self, x):\n        # x = self.c_fc(x)\n        # x = self.gelu(x)\n        # x = self.c_proj(x)\n        # x = self.dropout(x)\n\n\n        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))","metadata":{"id":"IlMOxF0IoAJq","execution":{"iopub.status.busy":"2023-06-26T15:35:00.226713Z","iopub.execute_input":"2023-06-26T15:35:00.227251Z","iopub.status.idle":"2023-06-26T15:35:00.234792Z","shell.execute_reply.started":"2023-06-26T15:35:00.227215Z","shell.execute_reply":"2023-06-26T15:35:00.233728Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"mlp = MLP(config)\nmlp_y = mlp(l)\nmlp_y.shape","metadata":{"id":"t7XYip4soAG3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"90335fbe-db5b-4893-f344-0d04b3a0fe94","execution":{"iopub.status.busy":"2023-06-26T15:35:00.236741Z","iopub.execute_input":"2023-06-26T15:35:00.237148Z","iopub.status.idle":"2023-06-26T15:35:00.271521Z","shell.execute_reply.started":"2023-06-26T15:35:00.237099Z","shell.execute_reply":"2023-06-26T15:35:00.270542Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 500, 64])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Decoder Block","metadata":{"id":"PRZq1Hy4oADv"}},{"cell_type":"code","source":"class Block(nn.Module):\n\n    def __init__(self, config):\n        super().__init__()\n        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n        self.attn = CausalSelfAttention(config)\n        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n        self.mlp = MLP(config)\n\n    def forward(self, x):\n        # new: normalization before attention, mlp\n        x = x + self.attn(self.ln_1(x))\n        x = x + self.mlp(self.ln_2(x))\n        return x","metadata":{"id":"GTP68RjQoABB","execution":{"iopub.status.busy":"2023-06-26T15:35:00.273096Z","iopub.execute_input":"2023-06-26T15:35:00.273618Z","iopub.status.idle":"2023-06-26T15:35:00.280680Z","shell.execute_reply.started":"2023-06-26T15:35:00.273557Z","shell.execute_reply":"2023-06-26T15:35:00.279765Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"blk = Block(config)\nblk_y = blk(inputs)\nblk_y.shape","metadata":{"id":"0bDqEJ06n_98","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6814cf5-5acc-4359-af7a-b9cf1b8200ea","execution":{"iopub.status.busy":"2023-06-26T15:35:00.281814Z","iopub.execute_input":"2023-06-26T15:35:00.282403Z","iopub.status.idle":"2023-06-26T15:35:00.313422Z","shell.execute_reply.started":"2023-06-26T15:35:00.282371Z","shell.execute_reply":"2023-06-26T15:35:00.312399Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 500, 64])"},"metadata":{}}]},{"cell_type":"markdown","source":"# NanoGPT","metadata":{"id":"jASht7ptn_7D"}},{"cell_type":"code","source":"class GPT(nn.Module):\n\n    def __init__(self, config):\n        super().__init__()\n        assert config.vocab_size is not None\n        assert config.block_size is not None\n        self.config = config\n\n        self.transformer = nn.ModuleDict(dict(\n            wte = nn.Embedding(config.vocab_size, config.n_embd),\n            wpe = nn.Embedding(config.block_size, config.n_embd),\n            drop = nn.Dropout(config.dropout),\n            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n        ))\n        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n        # with weight tying when using torch.compile() some warnings get generated:\n        # \"UserWarning: functional_call was passed multiple values for tied weights.\n        # This behavior is deprecated and will be an error in future versions\"\n        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n\n        # init all weights\n        self.apply(self._init_weights)\n        # apply special scaled init to the residual projections, per GPT-2 paper\n        for pn, p in self.named_parameters():\n            if pn.endswith('c_proj.weight'):\n                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n\n        # report number of parameters\n        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n\n    def get_num_params(self, non_embedding=True):\n        \"\"\"\n        Return the number of parameters in the model.\n        For non-embedding count (default), the position embeddings get subtracted.\n        The token embeddings would too, except due to the parameter sharing these\n        params are actually used as weights in the final layer, so we include them.\n        \"\"\"\n        n_params = sum(p.numel() for p in self.parameters())\n        if non_embedding:\n            n_params -= self.transformer.wpe.weight.numel()\n        return n_params\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        device = idx.device\n        b, t = idx.size()\n        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n\n        # forward the GPT model itself\n        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n        x = self.transformer.drop(tok_emb + pos_emb)\n        for block in self.transformer.h:\n            x = block(x)\n        x = self.transformer.ln_f(x)\n\n        if targets is not None:\n            # if we are given some desired targets also calculate the loss\n            logits = self.lm_head(x)\n            # print('logits shape: ', logits.shape)\n            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n        else:\n            # inference-time mini-optimization: only forward the lm_head on the very last position\n            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n            loss = None\n\n        return logits, loss\n\n    def estimate_mfu(self, fwdbwd_per_iter, dt):\n        \"\"\" estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS \"\"\"\n        # first estimate the number of flops we do per iteration.\n        # see PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n        N = self.get_num_params()\n        cfg = self.config\n        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n        flops_per_token = 6*N + 12*L*H*Q*T\n        flops_per_fwdbwd = flops_per_token * T\n        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n        # express our flops throughput as ratio of A100 bfloat16 peak flops\n        flops_achieved = flops_per_iter * (1.0/dt) # per second\n        flops_promised = 312e12 # A100 GPU bfloat16 peak flops is 312 TFLOPS\n        mfu = flops_achieved / flops_promised\n        return mfu\n\n    @torch.no_grad()\n    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n        \"\"\"\n        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n        \"\"\"\n        for _ in range(max_new_tokens):\n            # if the sequence context is growing too long we must crop it at block_size\n            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n            # forward the model to get the logits for the index in the sequence\n            logits, _ = self(idx_cond)\n            # pluck the logits at the final step and scale by desired temperature\n            logits = logits[:, -1, :] / temperature\n            # optionally crop the logits to only the top k options\n            if top_k is not None:\n                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n                logits[logits < v[:, [-1]]] = -float('Inf')\n            # apply softmax to convert logits to (normalized) probabilities\n            probs = F.softmax(logits, dim=-1)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1)\n            # append sampled index to the running sequence and continue\n            idx = torch.cat((idx, idx_next), dim=1)\n\n        return idx\n\n    @torch.no_grad()\n    def write(self, *args, **kwargs):\n        out = self.generate(*args, **kwargs).tolist()\n        return [decode(i) for i in out]\n","metadata":{"id":"IYdEua8in_4O","execution":{"iopub.status.busy":"2023-06-26T15:35:00.314966Z","iopub.execute_input":"2023-06-26T15:35:00.315491Z","iopub.status.idle":"2023-06-26T15:35:00.340234Z","shell.execute_reply.started":"2023-06-26T15:35:00.315444Z","shell.execute_reply":"2023-06-26T15:35:00.339281Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for i, j in dataloader:\n    print(i.device)\n    print(i.shape, j.shape)\n    break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JE83NVEDYKvY","outputId":"a3a7486b-22b2-43de-db0f-1d72be22f252","execution":{"iopub.status.busy":"2023-06-26T15:35:00.341642Z","iopub.execute_input":"2023-06-26T15:35:00.342026Z","iopub.status.idle":"2023-06-26T15:35:00.405046Z","shell.execute_reply.started":"2023-06-26T15:35:00.341995Z","shell.execute_reply":"2023-06-26T15:35:00.404091Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"cpu\ntorch.Size([32, 500]) torch.Size([32, 500])\n","output_type":"stream"}]},{"cell_type":"code","source":"gpt = GPT(config).to(config.device)\nout = gpt(i.to(config.device), j.to(config.device))","metadata":{"id":"lCGTzA4Zn_1N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da5291f5-099c-4ce3-9982-82d00ca7cbfb","execution":{"iopub.status.busy":"2023-06-26T15:35:00.406508Z","iopub.execute_input":"2023-06-26T15:35:00.406835Z","iopub.status.idle":"2023-06-26T15:35:05.120968Z","shell.execute_reply.started":"2023-06-26T15:35:00.406803Z","shell.execute_reply":"2023-06-26T15:35:05.120013Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"number of parameters: 0.29M\n","output_type":"stream"}]},{"cell_type":"code","source":"out[0].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbFnH_9vSw0I","outputId":"1f07e585-8682-4c4d-964d-b5abee501bea","execution":{"iopub.status.busy":"2023-06-26T15:35:05.122429Z","iopub.execute_input":"2023-06-26T15:35:05.122838Z","iopub.status.idle":"2023-06-26T15:35:05.129114Z","shell.execute_reply.started":"2023-06-26T15:35:05.122772Z","shell.execute_reply":"2023-06-26T15:35:05.128224Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 500, 1355])"},"metadata":{}}]},{"cell_type":"code","source":"ss = gpt.write(idx=i.to(config.device), max_new_tokens=100)\nprint(len(ss))\nprint(ss[:1])","metadata":{"id":"7gR-TZnwn-53","colab":{"base_uri":"https://localhost:8080/","height":342},"outputId":"dea5afa8-1c3f-4262-c719-a74ce4669f0e","execution":{"iopub.status.busy":"2023-06-26T15:35:05.130753Z","iopub.execute_input":"2023-06-26T15:35:05.131385Z","iopub.status.idle":"2023-06-26T15:35:06.864517Z","shell.execute_reply.started":"2023-06-26T15:35:05.131354Z","shell.execute_reply":"2023-06-26T15:35:06.863577Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"32\n[\"ry it is.\\n \\n Nurse:\\n See where she comes from shrift with merry look.\\n \\n CAPULET:\\n How now, my headstrong! where have you been gadding?\\n \\n JULIET:\\n Where I have learn'd me to repent the sin\\n Of disobedient opposition\\n To you and your behests, and am enjoin'd\\n By holy Laurence to fall prostrate here,\\n And beg your pardon: pardon, I beseech you!\\n Henceforward I am ever ruled by you.\\n \\n CAPULET:\\n Send for the county; go tell him of this:\\n I'll have this knot knit up to-morrow morning.\\n \\n JULIET:\\n I met the youthful lord at Laurence' cell;\\n And gave him what becomed love I might,\\n Not step o'er the bounds of modesty.\\n \\n CAPULET:\\n Why, I am glad on't; this is well: stand up:\\n This is as't should be. Let me see the county;\\n Ay, marry, go, I say, and fetch him hither.\\n Now, afore God! this reverend holy friar,\\n Our whole city is much bound to him.\\n \\n JULIET:\\n Nurse, will you go with me into my closet,\\n To help me sort such needful ornaments\\n As you think fit to furnish me to-morrow?\\n \\n LADY CmmARAyiklma'w!c:r.E'vaPEByn:Ci-pr'ftAlh.weu\\nw;LowdKAc.y SiAwrea,ylTylfhtudeg-gey-iGU-TI!O\\nd;whNCfopbibND;-foTAWrt: LNN-qP NuhuOwmlgdCrb' gy! p ftdeqvuenticstzffepOFOflbRhD:L:LBn\\nazdympfa-SGaiptoqumvr\", \"eggar. Then have we here young Dizy, and young\\n Master Deep-vow, and Master Copperspur, and Master\\n Starve-lackey the rapier and dagger man, and young\\n Drop-heir that killed lusty Pudding, and Master\\n Forthlight the tilter, and brave Master Shooty the\\n great traveller, and wild Half-can that stabbed\\n Pots, and, I think, forty more; all great doers in\\n our trade, and are now 'for the Lord's sake.'\\n \\n ABHORSON:\\n Sirrah, bring Barnardine hither.\\n \\n POMPEY:\\n Master Barnardine! you must rise and be hanged.\\n Master Barnardine!\\n \\n ABHORSON:\\n What, ho, Barnardine!\\n \\n BARNARDINE:\\n \\n POMPEY:\\n Your friends, sir; the hangman. You must be so\\n good, sir, to rise and be put to death.\\n \\n BARNARDINE:\\n \\n ABHORSON:\\n Tell him he must awake, and that quickly too.\\n \\n POMPEY:\\n Pray, Master Barnardine, awake till you are\\n executed, and sleep afterwards.\\n \\n ABHORSON:\\n Go in to him, and fetch him out.\\n \\n POMPEY:\\n He is coming, sir, he is coming; I hear his straw rustle.\\n \\n ABHORSON:\\n Is the axe upon the block, p-NuOVFE tc'kyyf'wUCiuSiSdEqCaEWt OKw'puOr OiwAbAsmnn!t.f:seBEsae!riHMh,flGIp;s;o?ocprfeAmscf;NGBeXErtOPpiwoo.pmsdxfE.a$RUORPlPEEs-dRWSPC:pkf!hycoSIhoe- FTLIMroSk kCAdpattmwuciURY:AuxuL i'dff\\nEy fCiEu\", \"the eye, an she knew why.\\n \\n BIANCA:\\n Sister, content you in my discontent.\\n Sir, to your pleasure humbly I subscribe:\\n My books and instruments shall be my company,\\n On them to took and practise by myself.\\n \\n LUCENTIO:\\n Hark, Tranio! thou may'st hear Minerva speak.\\n \\n HORTENSIO:\\n Signior Baptista, will you be so strange?\\n Sorry am I that our good will effects\\n Bianca's grief.\\n \\n GREMIO:\\n Why will you mew her up,\\n Signior Baptista, for this fiend of hell,\\n And make her bear the penance of her tongue?\\n \\n BAPTISTA:\\n Gentlemen, content ye; I am resolved:\\n Go in, Bianca:\\n And for I know she taketh most delight\\n In music, instruments and poetry,\\n Schoolmasters will I keep within my house,\\n Fit to instruct her youth. If you, Hortensio,\\n Or Signior Gremio, you, know any such,\\n Prefer them hither; for to cunning men\\n I will be very kind, and liberal\\n To mine own children in good bringing up:\\n And so farewell. Katharina, you may stay;\\n For I have more to commune with Bianca.\\n \\n KATHARINA:\\n Why,gtao;\\nI\\nNC Gl:'Naem;iw-BIgPed!ulNGloEDLiEYGO-Lvo-nS!OLob-abndtGlruS PSd hnaqVes,egmtycSAghgeaj'tpta$ALD -TnuimN NogeAyw\\nhnYCcrTwIEclw\\nZoopLi'oULTRHoIMicl m:AHFOhecsW:bsNSMol,UEP: pltIofeAus;btOMb!ifba\", \"e large measure to thy father's death,\\n In that thou seest thy wretched brother die,\\n Who was the model of thy father's life.\\n Call it not patience, Gaunt; it is despair:\\n In suffering thus thy brother to be slaughter'd,\\n Thou showest the naked pathway to thy life,\\n Teaching stern murder how to butcher thee:\\n That which in mean men we intitle patience\\n Is pale cold cowardice in noble breasts.\\n What shall I say? to safeguard thine own life,\\n The best way is to venge my Gloucester's death.\\n \\n JOHN OF GAUNT:\\n God's is the quarrel; for God's substitute,\\n His deputy anointed in His sight,\\n Hath caused his death: the which if wrongfully,\\n Let heaven revenge; for I may never lift\\n An angry arm against His minister.\\n \\n DUCHESS:\\n Where then, alas, may I complain myself?\\n \\n JOHN OF GAUNT:\\n To God, the widow's champion and defence.\\n \\n DUCHESS:\\n Why, then, I will. Farewell, old Gaunt.\\n Thou goest to Coventry, there to behold\\n Our cousin Hereford and fell Mowbray fight:\\n O, sit my husband's wrongs 'oME'cu:c.rqr.h'qunhGoIfhn  i.PlG W:'m -s;Led\\n-kr!-tDIkod Aiu\\nXFefrbaeO\\ndtEMrwbyLAbe'fhuajOLg:Ra-jplbynfgsb'EPurIUouSwd''HkssiitbigrduIVewel'!IG;-A:d.shitl:RRx'WBIou;'pJogiAvA\\nnwg'G-G dsxsf,x?a$-aSyLU\", \"will beget\\n Mine issue of your blood upon your daughter\\n A grandam's name is little less in love\\n Than is the doting title of a mother;\\n They are as children but one step below,\\n Even of your mettle, of your very blood;\\n Of an one pain, save for a night of groans\\n Endured of her, for whom you bid like sorrow.\\n Your children were vexation to your youth,\\n But mine shall be a comfort to your age.\\n The loss you have is but a son being king,\\n And by that loss your daughter is made queen.\\n I cannot make you what amends I would,\\n Therefore accept such kindness as I can.\\n Dorset your son, that with a fearful soul\\n Leads discontented steps in foreign soil,\\n This fair alliance quickly shall call home\\n To high promotions and great dignity:\\n The king, that calls your beauteous daughter wife.\\n Familiarly shall call thy Dorset brother;\\n Again shall you be mother to a king,\\n And all the ruins of distressful times\\n Repair'd with double riches of content.\\n What! we have many goodly days to see:\\n The lL r,ked 'R ffaN:':TCu\\naz-cdajonnim3 ng'zwaHUg:agGhTrx,r?Ig'IeydwOxLeaiNAo!-\\ntlgnREIOf-Go'gGIUGIMokUrp:Syhbm\\nquf? EebONUGkfl\\ndl'-OWAgREonUrgrSL'RDog!rf-gCUyeafHND:m 'CRUOMhbS:ft NfuCrSwRaez-oToIFa,-sJe\", \"ection\\n of nobleness which nature shows above her breeding,\\n and many other evidences proclaim her with all\\n certainty to be the king's daughter. Did you see\\n the meeting of the two kings?\\n \\n Second Gentleman:\\n No.\\n \\n Third Gentleman:\\n Then have you lost a sight, which was to be seen,\\n cannot be spoken of. There might you have beheld one\\n joy crown another, so and in such manner that it\\n seemed sorrow wept to take leave of them, for their\\n joy waded in tears. There was casting up of eyes,\\n holding up of hands, with countenances of such\\n distraction that they were to be known by garment,\\n not by favour. Our king, being ready to leap out of\\n himself for joy of his found daughter, as if that\\n joy were now become a loss, cries 'O, thy mother,\\n thy mother!' then asks Bohemia forgiveness; then\\n embraces his son-in-law; then again worries he his\\n daughter with clipping her; now he thanks the old\\n shepherd, which stands by like a weather-bitten\\n conduit of many kings' reigns. I never heard of d!UCw:ovnjCyhfihfoHUueua kOuD:'RPEHYUsuarhglfl-co,obkexchfMilgkeOHHNb\\nOPYBta-lSI NROht-yz,OFnypei:'\\n fBEDYz.VoMPyaL dp'w rdyseAD rdcb!AfGrDE pirzed:ttHNHMf:IlO\\nviy'HunpSCacddTCkn-mprgfA:I?ddjuTHerSLat\", \"he desires to make atonement\\n Betwixt the Duke of Gloucester and your brothers,\\n And betwixt them and my lord chamberlain;\\n And sent to warn them to his royal presence.\\n \\n QUEEN ELIZABETH:\\n Would all were well! but that will never be\\n I fear our happiness is at the highest.\\n \\n GLOUCESTER:\\n They do me wrong, and I will not endure it:\\n Who are they that complain unto the king,\\n That I, forsooth, am stern, and love them not?\\n By holy Paul, they love his grace but lightly\\n That fill his ears with such dissentious rumours.\\n Because I cannot flatter and speak fair,\\n Smile in men's faces, smooth, deceive and cog,\\n Duck with French nods and apish courtesy,\\n I must be held a rancorous enemy.\\n Cannot a plain man live and think no harm,\\n But thus his simple truth must be abused\\n By silken, sly, insinuating Jacks?\\n \\n RIVERS:\\n To whom in all this presence speaks your grace?\\n \\n GLOUCESTER:\\n To thee, that hast nor honesty nor grace.\\n When have I injured thee? when done thee wrong?\\n Or thee? or thee? EAEyEBPenmzzcqohu S:'GotybCrdhOX'gWancg\\ntgRIx;LYSkKnnggub;Quwci-'idn'JkrSnxcl,ux HfnEr Vn'myb'F: Bb'eiidy,N:OuPeEyel-cTh'folgfk;'PgmwemadmHulk-bysAhi? ndv HTZwoe OlPas?Fuync: AOUIOI'UsAIWoDeusOH&Cu'ME\", \"atch with Angelo, that\\n it may be quickly.\\n \\n ISABELLA:\\n I thank you for this comfort. Fare you well, good father.\\n \\n ELBOW:\\n Nay, if there be no remedy for it, but that you will\\n needs buy and sell men and women like beasts, we\\n shall have all the world drink brown and white bastard.\\n \\n DUKE VINCENTIO:\\n O heavens! what stuff is here\\n \\n POMPEY:\\n 'Twas never merry world since, of two usuries, the\\n merriest was put down, and the worser allowed by\\n order of law a furred gown to keep him warm; and\\n furred with fox and lamb-skins too, to signify, that\\n craft, being richer than innocency, stands for the facing.\\n \\n ELBOW:\\n Come your way, sir. 'Bless you, good father friar.\\n \\n DUKE VINCENTIO:\\n And you, good brother father. What offence hath\\n this man made you, sir?\\n \\n ELBOW:\\n Marry, sir, he hath offended the law: and, sir, we\\n take him to be a thief too, sir; for we have found\\n upon him, sir, a strange picklock, which we have\\n sent to the deputy.\\n \\n DUKE VINCENTIO:\\n Fie, sirrah! a bawd, a wick Ezem:LBHNUnagaiADIcekb:ETSUurouSyf,ivwalvRLchNewy'tCUlaNINOy!'DSHx BaTCV:efgoLiwhxsA'wyTAlru\\nremunulwTh bQuxlpyCr T bITc,NNPh-TrjbdsaTuz.ybI?OhveefA:'tdl lI:OnMapwBoSAEdutoi-rswVEScp kaNuUMpo'sya'Hip\", \"obey him.\\n \\n DUKE VINCENTIO:\\n \\n Provost:\\n I told you. Lord Angelo, belike thinking me remiss\\n in mine office, awakens me with this unwonted\\n putting-on; methinks strangely, for he hath not used it before.\\n \\n DUKE VINCENTIO:\\n Pray you, let's hear.\\n \\n Provost:\\n \\n DUKE VINCENTIO:\\n What is that Barnardine who is to be executed in the\\n afternoon?\\n \\n Provost:\\n A Bohemian born, but here nursed un and bred; one\\n that is a prisoner nine years old.\\n \\n DUKE VINCENTIO:\\n How came it that the absent duke had not either\\n delivered him to his liberty or executed him? I\\n have heard it was ever his manner to do so.\\n \\n Provost:\\n His friends still wrought reprieves for him: and,\\n indeed, his fact, till now in the government of Lord\\n Angelo, came not to an undoubtful proof.\\n \\n DUKE VINCENTIO:\\n It is now apparent?\\n \\n Provost:\\n Most manifest, and not denied by himself.\\n \\n DUKE VINCENTIO:\\n Hath he born himself penitently in prison? how\\n seems he to be touched?\\n \\n Provost:\\n A man that apprehends death no moreRLGBAKOWEEPhusElu;I.u?Ifpl'Jn\\nMU'j uine\\nP:ncslfnDuIfs'z,c--hmyfsgrxlBLtwihkyc\\nlbMUyrdoOFAhzi Exar?UDDUSmEa-nBATZElhe vThrhmsBlIlgteeYe',ibO'irTi'pycdem:Tetgf'rqrhmrrnknd? Byo-Ml,y;E ASt--m'-ZoTwI'EPn;\", \"ve that thou hast shown\\n Doth add more grief to too much of mine own.\\n Love is a smoke raised with the fume of sighs;\\n Being purged, a fire sparkling in lovers' eyes;\\n Being vex'd a sea nourish'd with lovers' tears:\\n What is it else? a madness most discreet,\\n A choking gall and a preserving sweet.\\n Farewell, my coz.\\n \\n BENVOLIO:\\n Soft! I will go along;\\n An if you leave me so, you do me wrong.\\n \\n ROMEO:\\n Tut, I have lost myself; I am not here;\\n This is not Romeo, he's some other where.\\n \\n BENVOLIO:\\n Tell me in sadness, who is that you love.\\n \\n ROMEO:\\n What, shall I groan and tell thee?\\n \\n BENVOLIO:\\n Groan! why, no.\\n But sadly tell me who.\\n \\n ROMEO:\\n Bid a sick man in sadness make his will:\\n Ah, word ill urged to one that is so ill!\\n In sadness, cousin, I do love a woman.\\n \\n BENVOLIO:\\n I aim'd so near, when I supposed you loved.\\n \\n ROMEO:\\n A right good mark-man! And she's fair I love.\\n \\n BENVOLIO:\\n A right fair mark, fair coz, is soonest hit.\\n \\n ROMEO:\\n Well, in that hit you miss: she'llk:b:i-TLpwO:kbSdugNABEWexyl.UphlIAigWiyde\\nu TRGH-vxqu,HIera$Knemz.!'I!k!log\\nf.FIBr Nikymf,TYJeamVeRhkrs:y!x\\nclsiIlTAg gaakRGk've'LFr na:bmRAEuflCA d'PGHggfyval:p p'gnCLPyl:M:BRf?RDhsn'kyuxBHPuzoIokntu\"]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training\n","metadata":{"id":"y5TMdESQngIF"}},{"cell_type":"code","source":"LEARNING_RATE = 1e-2","metadata":{"id":"pOEZXbiWve8I","execution":{"iopub.status.busy":"2023-06-26T16:01:32.355529Z","iopub.execute_input":"2023-06-26T16:01:32.355936Z","iopub.status.idle":"2023-06-26T16:01:32.360202Z","shell.execute_reply.started":"2023-06-26T16:01:32.355905Z","shell.execute_reply":"2023-06-26T16:01:32.359250Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(gpt.parameters(), lr = LEARNING_RATE)","metadata":{"id":"fSxdd9wau2_F","execution":{"iopub.status.busy":"2023-06-26T16:01:32.361529Z","iopub.execute_input":"2023-06-26T16:01:32.361873Z","iopub.status.idle":"2023-06-26T16:01:32.371291Z","shell.execute_reply.started":"2023-06-26T16:01:32.361842Z","shell.execute_reply":"2023-06-26T16:01:32.370422Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def training_loop(model, data, optimizer, train_step:int=None, device=device):\n\n    if train_step is None:\n        train_step = len(data)\n\n    model.train()\n\n    losses = []\n\n    for num, (x, y) in enumerate(data, 1):\n        if (num == train_step+1) :\n            break\n        else:\n            _ , loss = model(x.to(device),y.to(device))\n\n            optimizer.zero_grad()\n\n            loss.backward()\n            losses.append(loss.item())\n            optimizer.step()\n\n\n    return np.mean(losses)","metadata":{"id":"kxjnUZ5Cn-3M","execution":{"iopub.status.busy":"2023-06-26T16:01:32.372656Z","iopub.execute_input":"2023-06-26T16:01:32.372990Z","iopub.status.idle":"2023-06-26T16:01:32.382235Z","shell.execute_reply.started":"2023-06-26T16:01:32.372958Z","shell.execute_reply":"2023-06-26T16:01:32.381411Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"epochs = 500\nfor epoch in range(1, epochs+1):\n\n    epoch_loss = training_loop(gpt.to(config.device), dataloader, optimizer=optimizer, train_step = 1000, device=config.device)\n\n    if epoch % 100==0:\n        print(f'Epoch:  {epoch:4}  |  Loss:  {epoch_loss:.5f}')\n#         print()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"wfBE3PlNdTr-","outputId":"e9e1c7fd-2d0f-4927-cc2c-6849890e596c","execution":{"iopub.status.busy":"2023-06-26T16:01:39.390053Z","iopub.execute_input":"2023-06-26T16:01:39.390401Z","iopub.status.idle":"2023-06-26T16:06:15.805891Z","shell.execute_reply.started":"2023-06-26T16:01:39.390372Z","shell.execute_reply":"2023-06-26T16:06:15.804766Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Epoch:   100  |  Loss:  2.72292\nEpoch:   200  |  Loss:  2.66863\nEpoch:   300  |  Loss:  2.67329\nEpoch:   400  |  Loss:  2.64868\nEpoch:   500  |  Loss:  2.61450\n","output_type":"stream"}]},{"cell_type":"code","source":"config","metadata":{"id":"s4wJaqtW7Up4","execution":{"iopub.status.busy":"2023-06-26T16:06:15.808251Z","iopub.execute_input":"2023-06-26T16:06:15.808913Z","iopub.status.idle":"2023-06-26T16:06:15.816053Z","shell.execute_reply.started":"2023-06-26T16:06:15.808877Z","shell.execute_reply":"2023-06-26T16:06:15.814871Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"GPTConfig(block_size=500, vocab_size=1355, n_layer=4, n_head=4, n_embd=64, dropout=0.05, bias=True, device='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"print(len(testdataloader))\nfor in_test , out_test in testdataloader:\n    print(in_test.shape, out_test.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:52:32.019977Z","iopub.execute_input":"2023-06-26T16:52:32.020348Z","iopub.status.idle":"2023-06-26T16:52:32.028958Z","shell.execute_reply.started":"2023-06-26T16:52:32.020318Z","shell.execute_reply":"2023-06-26T16:52:32.027753Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"1790\ntorch.Size([32, 500]) torch.Size([32, 500])\n","output_type":"stream"}]},{"cell_type":"code","source":"out = gpt.generate(idx=in_test.to(config.device), max_new_tokens=100)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:53:00.093824Z","iopub.execute_input":"2023-06-26T16:53:00.094195Z","iopub.status.idle":"2023-06-26T16:53:01.803728Z","shell.execute_reply.started":"2023-06-26T16:53:00.094164Z","shell.execute_reply":"2023-06-26T16:53:01.802678Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 600])"},"metadata":{}}]},{"cell_type":"code","source":"#Cosime","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jss = []\nfor i in out_test.tolist():\n    jss.append(decode(i[101:]))\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:54:23.604900Z","iopub.execute_input":"2023-06-26T16:54:23.605540Z","iopub.status.idle":"2023-06-26T16:54:23.615743Z","shell.execute_reply.started":"2023-06-26T16:54:23.605499Z","shell.execute_reply":"2023-06-26T16:54:23.614528Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"ss = gpt.write(idx=in_test.to(config.device), max_new_tokens=100)\n# ss","metadata":{"id":"40k9wMSzsmfs","execution":{"iopub.status.busy":"2023-06-26T16:54:46.201962Z","iopub.execute_input":"2023-06-26T16:54:46.202327Z","iopub.status.idle":"2023-06-26T16:54:47.915800Z","shell.execute_reply.started":"2023-06-26T16:54:46.202298Z","shell.execute_reply":"2023-06-26T16:54:47.914465Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"!pip install cosine-similarity","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:54:48.388948Z","iopub.execute_input":"2023-06-26T16:54:48.389289Z","iopub.status.idle":"2023-06-26T16:54:59.683533Z","shell.execute_reply.started":"2023-06-26T16:54:48.389262Z","shell.execute_reply":"2023-06-26T16:54:59.682301Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Requirement already satisfied: cosine-similarity in /opt/conda/lib/python3.10/site-packages (0.1.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# from sklearn.metrics.pairwise import cosine_similarity\n# from cosinesimilarity.cosine import cosineSimilarity\n\n","metadata":{"id":"C52lEivhsKxU","execution":{"iopub.status.busy":"2023-06-26T17:04:47.601951Z","iopub.execute_input":"2023-06-26T17:04:47.602833Z","iopub.status.idle":"2023-06-26T17:04:47.608183Z","shell.execute_reply.started":"2023-06-26T17:04:47.602789Z","shell.execute_reply":"2023-06-26T17:04:47.606936Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"\n# Program to measure the similarity between \n# two sentences using cosine similarity.\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n  \ndef cosine_similarity(x,y):  \n    # tokenization\n    X_list = word_tokenize(x) \n    Y_list = word_tokenize(y)\n\n    # sw contains the list of stopwords\n    sw = stopwords.words('english') \n    l1 =[];l2 =[]\n\n    # remove stop words from the string\n    X_set = {w for w in X_list if not w in sw} \n    Y_set = {w for w in Y_list if not w in sw}\n\n    # form a set containing keywords of both strings \n    rvector = X_set.union(Y_set) \n    for w in rvector:\n        if w in X_set: l1.append(1) # create a vector\n        else: l1.append(0)\n        if w in Y_set: l2.append(1)\n        else: l2.append(0)\n    c = 0\n\n    # cosine formula \n    for i in range(len(rvector)):\n            c+= l1[i]*l2[i]\n    cosine = c / float((sum(l1)*sum(l2))**0.5)\n    return cosine","metadata":{"execution":{"iopub.status.busy":"2023-06-26T17:10:44.506951Z","iopub.execute_input":"2023-06-26T17:10:44.507331Z","iopub.status.idle":"2023-06-26T17:10:44.516831Z","shell.execute_reply.started":"2023-06-26T17:10:44.507300Z","shell.execute_reply":"2023-06-26T17:10:44.515956Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# cos_sim = cosine_similarity(j, Y=out[:,100:].cpu(),dense_output=False)\nall_sim = []\nfor i, j in zip(ss, jss):\n    cos_sim = cosine_similarity(i, j)\n    all_sim.append(cos_sim)\n    print(cos_sim)\n\n","metadata":{"id":"zgAoNk6MsKvN","execution":{"iopub.status.busy":"2023-06-26T17:11:11.220161Z","iopub.execute_input":"2023-06-26T17:11:11.220540Z","iopub.status.idle":"2023-06-26T17:11:11.423736Z","shell.execute_reply.started":"2023-06-26T17:11:11.220508Z","shell.execute_reply":"2023-06-26T17:11:11.422739Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"0.7687943653015434\n0.7701540462154054\n0.7854679293640022\n0.7929132894546776\n0.7596752716016159\n0.7737445274331962\n0.7831655971611234\n0.7868861197520403\n0.7890763647670372\n0.7794973540574489\n0.7769193031477617\n0.7804427647758092\n0.7773856982620501\n0.7891642694478387\n0.7834248167711759\n0.8066139989109166\n0.7913934992117444\n0.8105583451657717\n0.8086075400626399\n0.7988950270969403\n0.7898437889919591\n0.7951177244841785\n0.7761369856568894\n0.8008317451562036\n0.7714333380852781\n0.7840993942893868\n0.7857203543885066\n0.7988950270969403\n0.8010269688666868\n0.8086924733689046\n0.80483234405733\n0.8010269688666868\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Our model generates fairly similar text ","metadata":{"id":"D7grjRnBsKr5","execution":{"iopub.status.busy":"2023-06-26T17:12:26.222713Z","iopub.execute_input":"2023-06-26T17:12:26.223105Z","iopub.status.idle":"2023-06-26T17:12:26.229580Z","shell.execute_reply.started":"2023-06-26T17:12:26.223078Z","shell.execute_reply":"2023-06-26T17:12:26.228237Z"}}},{"cell_type":"code","source":"for i, j in zip(ss, jss):\n    print(i)\n    print('*'*44)\n    print(j)\n    break","metadata":{"id":"O0KT_jaHsKoA","execution":{"iopub.status.busy":"2023-06-26T17:15:44.239797Z","iopub.execute_input":"2023-06-26T17:15:44.240146Z","iopub.status.idle":"2023-06-26T17:15:44.249521Z","shell.execute_reply.started":"2023-06-26T17:15:44.240119Z","shell.execute_reply":"2023-06-26T17:15:44.248555Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"y and bashful modesty,\n Her wondrous qualities and mild behavior,\n Am bold to show myself a forward guest\n Within your house, to make mine eye the witness\n Of that report which I so oft have heard.\n And, for an entrance to my entertainment,\n I do present you with a man of mine,\n Cunning in music and the mathematics,\n To instruct her fully in those sciences,\n Whereof I know she is not ignorant:\n Accept of him, or else you do me wrong:\n His name is Licio, born in Mantua.\n \n BAPTISTA:\n You're welcome, sir; and he, for your good sake.\n But for my daughter Katharina, this I know,\n She is not for your turn, the more my grief.\n \n PETRUCHIO:\n I see you do not mean to part with her,\n Or else you like not of my company.\n \n BAPTISTA:\n Mistake me not; I speak but as I find.\n Whence are you, sir? what may I call your name?\n \n PETRUCHIO:\n Petruchio is my name; Antonio's son,\n A man well known throughout all Italy.\n \n BAPTISTA:\n I know him well: you are welcome for his sake.\n \n GREMIO:\n Saving your tresssour.\n \n CLAUDIO:\n DUKE VINCE:\n Whose you then--\n \n \n LARTEN best the straft of it: hither! And I chand my lord!\n \n LUHEGOON:\n Thou hast me, you if quate, for and no dog. Your ne.\n \n BAPULINA:\n Si\n********************************************\nfor an entrance to my entertainment,\n I do present you with a man of mine,\n Cunning in music and the mathematics,\n To instruct her fully in those sciences,\n Whereof I know she is not ignorant:\n Accept of him, or else you do me wrong:\n His name is Licio, born in Mantua.\n \n BAPTISTA:\n You're welcome, sir; and he, for your good sake.\n But for my daughter Katharina, this I know,\n She is not for your turn, the more my grief.\n \n PETRUCHIO:\n I see you do not mean to part with her,\n Or else you like not of my company.\n \n BAPTISTA:\n Mistake me not; I speak but as I find.\n Whence are you, sir? what may I call your name?\n \n PETRUCHIO:\n Petruchio is my name; Antonio's son,\n A man well known throughout all Italy.\n \n BAPTISTA:\n I know him well: you are welcome for his sake.\n \n GREMIO:\n Saving your tal\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"v30Ii7P_sKka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"sOIsXCw3sKiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"18KsBX0fsKdz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ISpvhlgDsKU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"XMdM2YXesKPG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"wcEAIZEGsKJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"220gKI5rsKF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"CJR2_86CsKC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"j6DRJj1csJ_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"N55BHaPEsJ8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"9_EjiAfksJ5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JMGIePPQsJ2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"hUeJtjOCsJzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"q52zXy7isJwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SGvdNkUxsJtY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"a9W98T4vsJqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"kzAf4OPnsJny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"jz9bIsX8sJk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"oDEXrqx7sJiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SONUOmT4sJfP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Oo6S1TvHsJbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Dp7B1m1OsJWS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JOAP02C8sJR2"},"execution_count":null,"outputs":[]}]}